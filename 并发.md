# 并发

## 并发：介绍

线程有一个程序计数器（PC），记录程序从哪里获取指令。

每个线程有自己的一组用于计算的寄存器。所以，如果有两个线程运行在一个处理器上，从运行一个线程（T1）切换到另一个线程（T2）时，必定发生上下文切换。

线程之间的上下文切换类似于进程间的上下文切换。对于进程，我们将状态保存到进程控制块（PCB）。现在，需要一个或多个线程控制块（TCB），保存每个线程的状态。但是，与进程相比，线程之间的上下文切换有一点主要区别：地址空间保持不变（即不需要切换当前使用的页表）。

线程和进程之间的另一个主要区别在于栈。在简单的传统进程地址空间模型（单线程）中，只有一个栈，通常位于地址空间的底部。

然而，在多线程的进程中每个线程独立运行，当然可以调用各种例程来完成正在执行的任何工作。不是地址空间只有一个栈，而是每个线程都有一个栈。

![1614789162604](C:\Users\Silhouette76\Documents\Tencent Files\1548623884\FileRecv\MobileFile\1614789162604.jpg)

所有位于栈上的变量、参数、返回值和其他放在栈上的东西，将被放置在有时称为线程本地存储的地方，即相关线程的栈。

### 26.3 核心问题：不可控的调度

临界区是访问共享变量的代码片段，一定不能由多个线程同时执行。

我们真正想要的代码就是所谓的互斥。这个属性保证了如果一个线程在临界区内执行，其他线程将被阻止进入临界区。

### 26.4 原子性愿望

在指令上构建一个通用的集合，即所谓的同步原语。通过使用这些硬件同步原语，加上操作系统的一些帮助，我们将能够构建多线程代码，以同步和受控的方式访问临界区，从而可靠地产生正确的结果。

> 临界区是访问共享资源的一段代码，资源通常是一个变量或数据结构
>
> 竞态条件出现在多个执行线程大致同时进入临界区时，它们都是试图更新共享的数据结构，导致了令人惊讶的结果
>
> 不确定性程序由一个或多个竞态条件组成，程序的输出因运行而异，具体取决于哪些线程在何时运行。这导致结果不是确定的，，而我们通常期望计算机系统给出确定的结果。
>
> 为了避免这些问题，线程应该使用某种互斥原语。这样做可以保证只有一个线程进入临界区，从而避免出现竞态，并产生确定的程序输出。

### 锁

程序员在源代码中加锁，放在临界区周围，保证临界区能够像单条原子指令一样执行。

### 28.1 锁的基本思想

锁就是一个变量，因此我们需要声明一个某种类型的锁变量，才能使用。这个锁变量保存了锁在某一时刻的状态。

它要么是可用的，表示没有线程持有锁，要么是被占用的，表示有一个线程持有锁，在处于临界区。我们也可以保存其他的信息，比如持有锁的线程，或请求获取锁的线程队列，但这些信息会隐藏起来，锁的使用者不会发现。

### 28.2 Pthread锁

POSIX库将锁称为互斥量，因为它被用来提供线程之间的互斥。即当一个线程在临界区，它能够阻止其他线程进入直到本线程离开临界区。

不同于任何临界区都是由同一个大锁（粗粒度的锁策略），通常大家会用不同的锁保护不同的数据和机构，从而允许更多的线程进入临界区（细粒度的方案）。

### 28.4 评价锁

- 第一是锁是否能完成它的基本任务，即提供互斥。最基本的，锁是否有效，能够阻止多个线程进入临界区？
- 第二是公平性。当锁可用时，是否每一个竞争线程有公平的机会抢到锁？用另一个方式来看这个问题是检查更极端的情况，是否有竞争的线程会饿死，一直无法获得锁？
- 最后是性能，是使用锁之后增加的时间开销。有几种场景需要考虑。
  - 一种是没有竞争的情况，即只有一个线程抢锁、释放锁的开支如何？
  - 另外一种是一个CPU上多个线程竞争，性能如何？
  - 最后一种是多个CPU、多个线程竞争时的性能。

### 28.5 控制中断

最早提供的互斥解决方案之一，就是在临界区关闭中断。

这种方法要求我们允许所有调用线程执行特权操作（打开关闭中断），就会出现麻烦

- 第一，一个贪婪的程序可能在它开始时就调用lock（）从而独占处理器。更糟糕的情况是，恶意程序调用lock（）后，一直死循环。系统无法重新获得控制，只能重启系统。
- 第二，这种方案不支持多处理器。如果多个线程运行在不同的CPU上，每个线程都试图进入同一个临界区，关闭中断也没有作用。
- 第三，关闭中断导致中断丢失，可能会导致严重的系统问题。
- 最后一个不太重要的原因就是效率低。与正常指令执行相比，现代CPU对于关闭和打开中断的代码执行得较慢。

### 28.6 测试并设置指令（原子交换）

最简单的硬件支持是测试并设置指令，也叫做原子交换。

当第一个线程正处于临界区时，如果另一个线程调用lock（），它会在while循环中自旋等待，直到第一个线程调用unlock（）清空标志。然后等待的线程会退出while循环，设置标志，执行临界区代码。

如果两个线程都将标志设置为1，都能进入临界区的场景，没有满足最基本的要求：互斥

性能问题主要是线程在等待已经被持有的锁时，采用了自旋等待的技术，就是不停地检查标志的值。自旋等待在等待其他线程释放锁的时候会浪费时间。尤其是在单处理器上，一个等待线程等待的目标线程甚至无法运行。

### 28.7 实现可用的自旋锁

- 第一种场景，假设一个线程在运行，调用lock（），没有其他线程持有锁，所以flag是0.当调用TestAndSet（flag，1）方法，返回0，线程会跳出while循环，获取锁。同时也会原子的设置flag为1，标志锁已经被持有。当线程离开临界区，调用unlock（）将flag清理为0。
- 第二种场景，当某一个线程已经持有锁（即flag为1）。本线程调用lock（），然后调用TestAndSet（flag，1），这一次返回1。只要另一个线程一直持有锁，TestAndSet（）会重复返回1，本线程会一直自旋。当flag终于被改为0，本线程就会调用TestAndSet（），返回0并且原子地设置为1，从而获得锁，进入临界区。

将测试（test旧的锁值）和设置（set新的值）合并为一个原子操作之后，我们保证了只有一个线程能获取锁。

这是最简单的一种锁，一直自旋，利用CPU周期，直到锁可用。在单处理器上，需要抢占式的调度器。否则，自旋锁在单CPU上无法使用，因为一个自旋的线程永远不会放弃CPU。



### 28.8 评价自旋锁

- 互斥：自旋锁一次只允许一个线程进入临界区。这是正确的锁

- 公平性：自旋锁不提供任何公平性保证。实际上，自旋的线程在竞争条件下可能会永远自旋。自旋锁没有公平性，可能会导致饿死。
- 性能：
  - 对于自旋锁，在单CPU的情况下 ，性能开销相当大。假设一个线程持有锁进入临界区时被抢占。调度器可能会允许其他每一个线程。而其他线程都在竞争锁，都会在放弃CPU之前，自旋一个时间片浪费CPU周期。
  - 在多CPU上，自旋锁性能不错（如果线程数大致等于CPU数）。

### 28.9 比较并交换

某些系统提供了另一个硬件原语，即比较并交换指令。

比较并交换的基本思路时检测ptr指向的值2是否和expected相等；如果是，更新ptr所指的值为新值。否则，什么也不做，不论那种情况，都返回该内存地址的实际值，让调用者能够知道执行是否成功。

### 28.10 链接的加载和条件式存储指令

链接的加载和条件式存储可以用来配合使用，实现其他并发结构。

链接的加载指令和典型加载指令类似，都是从内存种取出值存入一个寄存器。关键区别来自条件式存储指令，只有上一次加载的地址在期间都没有更新时，才会成功，（同时更新刚才链接的加载的地址的值）。成功时，条件存储返回1，并将ptr指的值更新为value。失败时，返回0，并且不会更新值。

### 28.11 获取并增加

最后一个硬件原语是获取并增加指令，它能原子地返回特定地址的旧值，并且让该值自增一。

这个解决方案使用了ticket和turn变量来构建锁。

基本操作：如果线程希望获取锁，首先对一个ticket值执行一个原子的获取并相加指令。这个值作为该线程的“turn”根据全局共享的lock->turn变量，当某一个线程的（myturn==turn）时，则轮到这个线程进入临界区。unlock则是增加turn，从而下一个等待线程可以进入临界区。

不同于之前的方法：本方法能够保证所有线程都能抢到锁。只要一个线程获得了ticket值，它最终会被调度。

### 28.13 让出来吧，宝贝

在这种方法中，我们假定操作系统提供原语yield（）,线程可以调用它主动放弃CPU，让其他线程运行。线程可以处于3种状态之一。yield（）系统调用能够让运行态变为就绪态，从而允许其他线程运行。因此，让出线程本质上取消调度了它自己。

### 28.14 使用队列：休眠替代自旋

我们必须显示地施加某种控制，觉得锁释放时，谁能抢到锁。

利用Solaris提供的支持，它提供了两个调用：park（）能够让调用线程休眠，unpark（threadID）则会唤醒threadID标识的线程。

guard基本上起到了自旋锁的作用，围绕着flag和队列操作。因此，这个方法并没有完全避免自旋等待。线程在获取锁或者释放锁时可能被中断，从而导致其他线程自旋等待。但是，这个自旋等待时间是有限的。

在lock（）函数种，如果线程不能获取锁，线程会把自己加入队列，将guard设置为0，然后让CPU。

但是还存在竞争条件：如果该线程随后释放了锁，接下来第一个线程的park会永远睡下去。这种问题有时称为唤醒/等待竞争。为了避免这种情况，我们需要额外的工作。

Solaris通过增加了第三个系统调用setpark（），一个线程表明自己马上要park。如果刚好另一个线程被调度，并且调用了unpark，那么后续的park调用就会直接返回，而不是一直睡眠。

### 28.16 两阶段锁

两阶段锁的第一阶段会自旋一段时间，希望它可以获取锁。但是，如果第一自旋阶段没有获得锁，第二阶段调用者会睡眠，直到锁可用。



## 基于锁的并发数据结构

**对于特定数据结构，如何加锁才能让该结构功能正确？进一步，如何对该数据结果加锁，能够保证高性能，让许多线程同时访问该结构，即并发访问。**

### 29.1 并发计数器

计数器是最简单的一种数据结构，使用广泛而且接口简单。

*简单但无法扩展*

*可扩展的计数*

懒惰计数器通过多个局部计数器和一个全局计数器来实现一个逻辑计数器，其中每个CPU核心有一个局部计数器。具体来说，在4个CPU的机器上，有4个局部计数器和1个全局计数器。除了这些计数器，还有锁：每个局部计数器有一个锁，全局计数器有一个。

懒惰计数器的基本思想是这样的：如果一个核心上的线程想增加计数器，那就增加它的局部计数器，访问这个局部计数器是通过对应的局部锁同步的。因为每个CPU有自己的局部计数器，不同CPU上的线程不会竞争，所以计数器的更新操作可扩展性好。

但是，为了保持全局计数器更新（以防某个线程要读取该值），局部值会定期转移给全局计数器，方法是获取全局锁，让全局计数器加上局部计数器的值，然后将局部计数器置零。

这种局部转全局的频度，取决于一个阈值，这里称为S。S越小，懒惰计数器则越趋近于非扩展的计数器。S越大，扩展性越强，但是全局计数器与实际技术的偏差越大。

### 29.2 并发链表

*扩展链表*

尽管我们有了基本的并发链表，但又遇到了这个链表扩展性不好的问题。

研究人员发现的增加链表并发的技术中，有一种叫做过手锁，也叫锁耦合。

原理是：每个节点都有一个锁，替代之前整个链表一个锁。遍历链表的时候，首先抢占下一个节点的锁，然后释放当前节点的锁。

从概念上说，过手锁链表有点道理，它增加了链表操作的并发程度。但是实际上，在遍历的时候，每个节点获取锁、释放锁的开销巨大，很难比单锁的方法快。即使有大量的线程和很大的链表，这种并发的方案也不一定会比单锁的方案快。

> 如果方案带来了大量的开销（例如：频繁地获取锁、释放锁），那么高并发就没有什么意义。

### 29.3 并发队列

标准的方法创建一个并发数据结构：添加一大把锁。

在并发队列中，有两个锁，一个负责队列头，另一个负责队列尾。这里两个锁使得入队列操作和出队列操作可以并发执行，因为入队列只访问tail锁，而出队列只访问head锁。

在这里，作者添加了一个假节点（在队列初始化的代码里分配的）。该假节点分开了头和尾操作。

队列在多线程程序里广泛使用。然而，这个队列（只是加了锁）通常不能完全满足这种程序的需求。

### 29.4 并发散列表

每个散列表桶（每个桶都是一个链表）都有一个锁，而不是整个散列表只有一个锁，从而支持许多并发操作。

## 条件变量

锁并不是并发程序设计所需的唯一原语。具体来说，在很多情况下，线程需要检查某一条件满足之后，才会继续运行。

**多线程程序中，一个线程等待某些条件是很常见的。简单的方案是自旋直到条件满足，这是及其低效的，某些情况下甚至是错误的。那么 ，线程应该如何等待一个条件？**

### 30.1 定义和程序

线程可以使用条件变量，来等待一个条件变成真。条件变量是一个显示队列，当某些执行状态（即条件）不满足时，线程可以把自己加入队列，等待该条件。

另外某个线程，当它改变了上述状态时，就可以唤醒一个或者多个等待线程（通过在该条件上发信号），让它们继续执行。

条件变量有两种相关操作：wait（）和signal（）。线程要睡眠的时候，调用wait（）。当线程想唤醒等待在某个条件变量上的睡眠线程时，调用signal（）。

wait（）调用有一个参数，它是互斥量。它假定在wait（）调用时，这个互斥量是已上锁状态。wait（）的职责是释放锁，并让调用线程休眠（原子地）。当线程被唤醒时，它必须重新获取锁，再返回调用者。

有两种情况需要考虑：

- 第一种情况是父线程创建出子线程，但自己继续运行（假设只有一个处理器），然后马上调用thr_join（）等待子线程。在这种情况下，它会先获取锁，检查子线程是否完成（还没有完成），然后调用wait（），让自己休眠。子线程最终得以运行，打印出“child”，并调用thr_exit（）函数唤醒父进程，这段代码会在获得锁后设置状态变量done，然后向父线程发信号唤醒它。最后，父线程会进行，释放锁。
- 第二种情况是，子线程在创建后，立刻运行，设置变量done为1，调用signal函数唤醒其他线程（这里没有其他线程），然后结束。父线程运行后，调用thr_join（）时，发现done已经是1了，就直接返回了。

### 30.2 生产者/消费者（有界缓冲区）问题

假设有一个或多个生产者线程合一个或多个消费者线程。生产者把生成的数据项放入缓冲区，消费者从缓冲区取走数据项，以某种方式消费。

因为有界缓冲区是共享资源，所以我们必须通过机制来访问它，以免产生竞态条件

*最终的生产者/消费者方案*

最后的修改是提高并发和效率。具体来说，增加更多缓冲区槽位，这样在睡眠之前，可以生产多个值。同样，睡眠之前可以消费多个值。单个生产者和消费者时，这种方案因为上下文切换少，提高了效率。多个生产者和消费者时，它甚至支持并发生产和消费，从而提高了并发。

### 30.3 覆盖条件

用pthread_cond_broadcast()代替上述代码中的pthread_cond-signal()，唤醒所有的等待线程。这样做，确保了所有应该唤醒的线程都被唤醒。当然，不利的一面是可能会影响性能，因为不必要地唤醒了其他许多等待的线程，它们本来不应该被唤醒。这些线程被唤醒后，重新检查条件，马上再次睡眠。

这种条件变量叫做覆盖条件，因为它能覆盖所有需要唤醒线程的场景。

##  信号量

**如何使用信号量代替锁和条件变量？什么是信号量？什么是二值信号量？用锁和条件变量来实现信号量是否简单？不用锁和条件变量，如何实现信号量？**

### 31.1 信号量的定义

信号量是有一个整数值的对象，可以用两个函数来操作它。

在POSIX标准中，是sem_wait()和sem_post()。因为信号量的初始值能够决定其行为，所以首先要初始化信号量，才能调用其他函数与之交互。

```
#include<semaphore.h>
sem_t s;
sem_init(&s,0,1);
```

其中申明了一个信号量s，通过第三个参数，将它的值初始化为1。sem_init()的第二个参数，在我们看到的所有例子中都设置为0，表示信号量是在同一进程的多个线程共享的。 

sem_wait()要么立刻返回（调用sem_wait()时，信号量的值大于等于1），要么会让调用线程挂起，直到之后的一个post操作。当然，也可能多个调用线程都调用sem_wait()，因此都在队列中等待被唤醒。

sem_post()并没有等待某些条件满足。它直接增加信号量的值，如果有等待线程，唤醒其中一个。

当信号量的值为负数时，这个值就是等待线程的个数。虽然这个值通常不好暴露给信号量的使用者。

### 31.2 二值信号量（锁）

信号量的第一种用法是我们已经熟悉的：用信号量作为锁。

假设有两个线程的场景：

- 第一个线程（线程0）调用了sem_wait()，它把信号量的值减为0。然后，它只会在值小于0时等待。因为值是0，调用线程从函数返回并继续，线程0现在可以自由进入临界区。线程0在临界区总，如果没有其他线程尝试获取锁，当它调用sem_post()时，会将信号量重置为1（因为没有等待线程，不会唤醒其他线程）

![image-20210307172817330](C:\Users\Silhouette76\AppData\Roaming\Typora\typora-user-images\image-20210307172817330.png)

- 如果线程0持有锁，另一个线程（线程1）调用sem_wait()尝试进入临界区，那么更有趣的情况就发生了。在这种情况下，线程1把信号量减为-1，然后等待（自己睡眠，放弃处理器）。线程0再次运行，它最终调用sem_post()，将信号量的值增加到0，唤醒等待的线程（线程1），然后线程1就可以获取锁。线程1执行结束时，再次增加信号量的值，将它恢复为1。![image-20210307173135231](C:\Users\Silhouette76\AppData\Roaming\Typora\typora-user-images\image-20210307173135231.png)

因为锁只有两个状态（持有和没持有），所以这种用法有时也叫做二值信号量。

### 31.3 信号量用作条件变量

信号量也可以用在一个线程暂停执行，等待某一条件成立的场景。例如：一个线程要等待一个链表非空，然后才能删除一个元素。

假设一个线程创建另外一个线程，并且等待它结束。

```
sem_t s;
void *
child(void *arg){
printf("child\n");
sem_post(&s);
return NULL;
}

int main(int argc, char *argv[]){
sem_init(&s,0,X);
printf("parent:begin\n");
pthread_t c;
Pthread_create(c,NULL,child,NULL);
sem_wait(&s);
printf("parent\n");
return 0;
}
```

从代码中可知，父线程调用sem_wait()，子线程调用sem_post()，父线程等待子线程执行完成。但是，信号量的初始值应该是多少？

信号量的初始值应该是0。有两种情况需要考虑：

- 第一种：父线程创建了子线程，但是子线程并没有运行。

![image-20210308001019495](C:\Users\Silhouette76\AppData\Roaming\Typora\typora-user-images\image-20210308001019495.png)

- 第二种：子线程在父线程调用sem_wait()之前就运行结束。

![image-20210308001119688](C:\Users\Silhouette76\AppData\Roaming\Typora\typora-user-images\image-20210308001119688.png)

### 31.4 生产者/消费者（有界缓冲区问题）

*第一次尝试*

第一次尝试解决该问题时，用两个信号量empty和full分别表示缓冲区空或者满。

```
void put(); //生产者将数据放入缓冲区

void get(); //消费者从缓冲区中取出数据

sem_t empty;
sem_t full;

void *producer(void *arg) {
	int i;
	for(i = 0; i < loops; i++) {
		P(&empty);	//对empty信号量减1，empty<0停止生产
		put(i);		//将生产出的值放入缓冲区
		V(&full);	//对full信号量加1，full>1唤醒消费者
	}
}

void *consumer(void *arg) {
	int i, tmp = 0;
	while(tmp != -1) {
		P(&full);		//对full信号量减1，full<0停止消费
		tmp = get();	//将缓冲区内的值取出
		V(&empty);		//对empty信号量加1，empty>1唤醒生产者
	}
}

int main() {
	...
	sem_init(&empty, 0, MAX); //MAX为预期生产的数据个数
	sem_init(&full, 0, 0);
	...
}
```

假设MAX=1，验证程序是否有效。

假设有两个线程，一个生产者和一个消费者。

在单个CPU上的具体场景：消费者先运行，调用sem_wait(&full)。因为full初始值为0，wait调用会将full减为-1，导致消费者睡眠，等待另一个线程调用sem_post(&full)，符合预期 。

假设生产者后运行，调用sem_wait(&empty)。不像消费者，生产者将继续执行，因为empty被初始化为MAX（1）。因此，empty被减为0，生产者向缓冲区中加入数据，然后调用sem_post(&full)，发现缓冲区确实满了，消费它。这两种情况都是符合预期的。

问题是：假设MAX大于1，两个生产者（Pa和Pb）几乎同时调用put()。当Pa先运行，先加入第一条数据，假设Pa在将fill计数器更新为1之前被中断，Pb开始运行，也在缓冲区的0位置加入一条数据，这意味着旧数据会被覆盖。

*解决方案：增加互斥*

向缓冲区加入元素和增加缓冲区加入元素和增加缓冲区的索引是临界区，需要小心保护起来，使用二值信号量来增加锁

```
void put(); //生产者将数据放入缓冲区

void get(); //消费者从缓冲区中取出数据

sem_t empty;
sem_t full;
sem_t mutex;	//mutex互斥信号量作为锁

void *producer(void *arg) {
	int i;
	for(i = 0; i < loops; i++) {
		P(&mutex);	
		P(&empty);	//对empty信号量减1，empty<0停止生产
		put(i);		//将生产出的值放入缓冲区
		V(&full);	//对full信号量加1，full>1唤醒消费者
		V(&mutex);
	}
}

void *consumer(void *arg) {
	int i, tmp = 0;
	while(tmp != -1) {
		P(&mutex);
		P(&full);		//对full信号量减1，full<0停止消费
		tmp = get();	//将缓冲区内的值取出
		V(&empty);		//对empty信号量加1，empty>1唤醒生产者
		V(&mutex);
	}
}

int main() {
	...
	sem_init(&empty, 0, MAX); //MAX为预期生产的数据个数
	sem_init(&full, 0, 0);
	sem_init(&mutex, 0, 1); //新增的互斥信号量
	...
}
```

*避免死锁*

**为什么会发生死锁？**

假设有两个线程，一个生产者和一个消费者，消费者首先运行，获得锁，然后对full信号量执行sem_wait()。因为还没有数据，所以消费者阻塞，让出CPU，但是此时消费者还持有锁。

然后生产者运行，加入生产者能够运行，它就能生产数据并唤醒消费者线程，它先对二值互斥信号量sem_wait()调用，但此时锁已经被消费者持有，因此生产者也被卡住。

这里出现了循环等待：消费者持有互斥量，等待在full信号量上，生产者可以发送full信号，却在等待互斥量。因此，生产者和消费者互相等待对方——典型的死锁。

*可行的方案*

把获取和释放互斥量的操作调整为紧挨着临界区，把full、empty的唤醒和等待操作调整到锁外面。得到了简单而有效的有界缓冲区，多线程程序的常用模式。

```
void put(); //生产者将数据放入缓冲区

void get(); //消费者从缓冲区中取出数据

sem_t empty;
sem_t full;
sem_t mutex;	//mutex互斥信号量作为锁

void *producer(void *arg) {
	int i;
	for(i = 0; i < loops; i++) {
		P(&empty);	//对empty信号量减1，empty<0停止生产
		P(&mutex);	
		put(i);		//将生产出的值放入缓冲区
		V(&mutex);
		V(&full);	//对full信号量加1，full>1唤醒消费者
	}
}

void *consumer(void *arg) {
	int i, tmp = 0;
	while(tmp != -1) {
		P(&full);		//对full信号量减1，full<0停止消费
		P(&mutex);
		tmp = get();	//将缓冲区内的值取出
		V(&mutex);
		V(&empty);		//对empty信号量加1，empty>1唤醒生产者
	}
}

int main() {
	...
	sem_init(&empty, 0, MAX); //MAX为预期生产的数据个数
	sem_init(&full, 0, 0);
	sem_init(&mutex, 0, 1); //新增的互斥信号量
	...
}
```

### 31.5 读者—写者锁

读者—写者锁源于对更加灵活的锁定原语的渴望，它承认不同的数据结构访问可能需要不同类型的锁。

例如：一个并发链表有很多插入和查找操作。插入操作会修改链表的状态（因此传统的临界区有用），而查找操作只是读取该结构，只要没有进行插入操作，我们可以并发的执行多个查找操作。

```
typedef struct_rwlock_t {
	sem_t lock;			//读者锁
	sem_t writelock;	//写者锁
	int readers;
} rwlock_t;

void rwlock_init(rwlock_t *rw) {
	rw->readers = 0;
	sem_init(&rw->lock, 0, 1);		//初始化读者锁
	sem_init(&rw->writelock, 0, 1);	//初始化写者锁
}

//获取读者锁
//且第一个读者自动获取写者锁
void rwlock_acquire_readlock(rwlock_t *rw) {
	P(&rw->lock);
	rw->readers++;
	if(rw->readers == 1) {
		P(&rw->writelock);
	}
	V(rw->lock);
}

//获取写者锁
void rwlock_acquire_writelock(rwlock_t *rw) {
	P(&rw->writelock);
}

//释放写者锁
void rwlock_release_writelock(rwlock_t *rw) {
	V(rw->writelock);
}
```

获取读锁时，读者首先要获取lock，然后增加reader变量，追踪目前有多少个读者在访问该数据结构。重要的步骤在rwlock_acquire_readlock()内发生，当第一个读者获取该锁时，读者也会获取写锁，即在writelock信号量上调用sem_wait()，然后调用sem_post()释放lock。

一旦一个读者获得了读锁，其他的读者也可以获取这个读锁。但是，想要获取写锁的线程，就必须等到所有的读者都结束。最后一个退出的读者在“writelock”信号量上调用sem_post()，从而让等待的写者能够获取该锁 。

但这个锁有缺陷，缺乏公平性，读者很容易饿死写者，性能也没有优势，因为加入了更多的开锁。

### 31.6 哲学家就餐问题

哲学家就餐问题时一个著名的并发问题。

问题的基本情况是：假定有5位“哲学家”围着一个圆桌。每两位哲学家之间有一把餐叉（一共5把）。哲学家有时要思考一会，不需要餐叉；有时又要就餐。而一位哲学家只有同时拿到了左手边和右手边的两把餐叉，才能吃到东西。

## 常见并发问题

### 32.1 有哪些类型的缺陷

死锁和非死锁

### 32.2 非死锁缺陷

*违反原子性缺陷*

定义：违反了多次内存访问中预期的可串行性（即代码段本意是原子的，但在执行中并没有强制实现原子性）。

*违反顺序缺陷*

定义：两个内存访问的预期顺序被打破了（即A应该在B之前执行，但实际运行中却不是这个顺序）。

### 32.3 死锁缺陷

![image-20210308222103786](C:\Users\Silhouette76\AppData\Roaming\Typora\typora-user-images\image-20210308222103786.png)

*为什么会发生死锁*

其中一个原因是在大型的代码库里，组件之间会有复杂的依赖。以操作系统为例：虚拟内存系统在需要访问文件系统才能从磁盘读到内存页；文件系统随后又要和虚拟内存交互，去申请一页内存，以便存放读到的块。

另一个原因是封装。

*产生死锁的条件*

需要4个条件：

- 互斥：线程对于需要的资源进行互斥的访问（例如一个线程抢到锁）
- 持有并等待：线程持有了资源（例如已将持有的锁），同时又在等待其他资源（例如，需要获得的锁）
- 非抢占：线程获得的资源（例如锁），不能被抢占
- 循环等待：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请。

这4个条件的任何一个没有满足，死锁就不会产生。

*预防*

**循环等待**

最直接的方法就是获取锁时提供一个全序。假如系统共有两个锁（L1和L2），那么我们每次都先申请L1再申请L2就可以避免死锁。

但是锁的全序可能很难做到，因此偏序可能是一种有用的方法。

**持有并等待**

死锁的持有并等待条件，可以通过原子地抢锁来避免。

要保证在抢锁的过程中，不会有不合时宜的线程切换，从而避免了死锁。

**非抢占**

在调用unlock之前，都认为锁是被占有的，多个抢锁操作通常会带来麻烦，因为等待一个锁时，同时持有另一个锁。

```
top:
	lock(1);
	if(trylock(L2) == -1){
		unlock(L1);
		goto top;
	}
```

另一个线程可以使用相同的加锁方式，但是不同的加锁顺序（L2然后L1），程序仍然不会产生死锁。但会有新的问题：活锁。两个线程有可能已知重复这一序列，又同时都抢锁失败。这种情况下，系统一直在运行这段代码（因此不是死锁），但是又不会有进展，因此名为活锁。

也有解决的方法：可以在循环结束的时候，先随机等待一个时间，然后再重复整个动作，这样可以降低线程之间的重复互相干扰。

**互斥**

比较并交换指令

无须获取锁，更新值，然后释放锁这些操作，我们使用比较并交换指令，反复尝试将值更新到新的值。这种方式没有使用锁，因此不会有死锁（有可能产生活锁）。

*通过调度避免死锁*

除了预防死锁，某些场景更适合死锁避免。我们需要了解全局的信息，包括不同线程再运行中对锁的需求情况，从而使得后续的调度能够避免产生死锁。

![image-20210308225437969](C:\Users\Silhouette76\AppData\Roaming\Typora\typora-user-images\image-20210308225437969.png)

T1、T2和T3运行在同一个处理器上，这种保守的静态方案会明显增加完成任务的总时间。尽管有可能并发运行这些任务，但为了避免死锁，付出了性能的代价。

*检查和恢复*

最后一直常用策略就是允许死锁偶尔发生，检查到死锁时再采取行动。

很多数据库系统使用了死锁检测和恢复技术。死锁检测器会定期运行，通过构建资源图来检查循环。当循环（死锁）发生时，系统需要重启。如果还需要更复杂的数据结构相关的修复，那么需要人工参与。



































































